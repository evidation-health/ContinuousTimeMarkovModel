{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defines the complete model in David's paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate single trajectory up to X level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "N = 100\n",
    "M = 6\n",
    "K = 10\n",
    "D = 721\n",
    "Dd = 80\n",
    "\n",
    "min_obs = 10\n",
    "max_obs = 30\n",
    "\n",
    "np.random.seed(1729)\n",
    "T = np.random.choice(np.arange(min_obs-1,max_obs), N) + 1\n",
    "\n",
    "step_sizes = [1,2,4]\n",
    "\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%Rpush T N M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(smfsb)\n",
    "\n",
    "#initial state distribution\n",
    "pi <- c(0.147026,0.102571,0.239819,0.188710,0.267137,0.054738)\n",
    "#pi <- c(1,0,0,0,0,0)\n",
    "\n",
    "#transition rate matrix\n",
    "Q <- matrix(c(-0.631921,0.631921,0.000000,0.000000,0.000000,0.000000,\n",
    "    0.000000,-0.229485,0.229485,0.000000,0.000000,0.000000,\n",
    "    0.000000,0.000000,-0.450538,0.450538,0.000000,0.000000,\n",
    "    0.000000,0.000000,0.000000,-0.206042,0.206042,0.000000,\n",
    "    0.000000,0.000000,0.000000,0.000000,-0.609582,0.609582,\n",
    "    0.000000,0.000000,0.000000,0.000000,0.00001,-0.00001), nrow=M, ncol=M,byrow=TRUE)\n",
    "\n",
    "rcfmc_wrapper <- function(dummy){\n",
    "  return(rcfmc(M, Q, pi))\n",
    "}\n",
    "set.seed(1729)\n",
    "sampled_trajectories <- lapply(1:N, rcfmc_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make 1 the most likely step size to happen because\n",
    "#this is what David's data is like\n",
    "step_sizes = [1,1,1,1,1,1,1,1,2,4]\n",
    "np.random.seed(1729)\n",
    "  \n",
    "obs_jumps = np.zeros((N,max_obs-1), dtype=np.int) # Per user observed jumps in stages, sampled and zero-padded\n",
    "for user_num, Tn in zip(range(N),T):\n",
    "    obs_jumps[user_num,:(Tn-1)] = np.random.choice(step_sizes, Tn-1)\n",
    "\n",
    "obs_times = np.insert(np.cumsum(obs_jumps, axis=1),0,0, axis=1)\n",
    "%Rpush obs_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#zipped up index and matrix to use apply function\n",
    "index_and_obs_times <- cbind(1:100, obs_times)\n",
    "getS <- function(index_and_obs_times){\n",
    "  n_obs <- length(index_and_obs_times)\n",
    "  S <- sampled_trajectories[[index_and_obs_times[1]]](index_and_obs_times[2:n_obs])\n",
    "  return(S)\n",
    "}\n",
    "S <- apply(index_and_obs_times, 1, getS)\n",
    "S <- t(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%Rpull S\n",
    "S = S.astype(int) - 1\n",
    "\n",
    "if np.any(np.diff(S)<0):\n",
    "    raise Exception('S goes down a stage at some point!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "B = np.array([\n",
    "[0.000001,0.760000,0.720000,0.570000,0.700000,0.610000],\n",
    "[0.000001,0.460000,0.390000,0.220000,0.200000,0.140000],\n",
    "[0.000001,0.620000,0.620000,0.440000,0.390000,0.240000],\n",
    "[0.000001,0.270000,0.210000,0.170000,0.190000,0.070000],\n",
    "[0.000001,0.490000,0.340000,0.220000,0.160000,0.090000],\n",
    "[0.000001,0.620000,0.340000,0.320000,0.240000,0.120000],\n",
    "[0.000001,0.550000,0.390000,0.320000,0.290000,0.150000],\n",
    "[0.000001,0.420000,0.240000,0.170000,0.170000,0.110000],\n",
    "[0.000001,0.310000,0.300000,0.230000,0.190000,0.110000],\n",
    "[0.000001,0.470000,0.340000,0.190000,0.190000,0.110000]])\n",
    "\n",
    "B0 = np.array([\n",
    "[0.410412,0.410412,0.418293,0.418293,0.429890,0.429890],\n",
    "[0.240983,0.240983,0.240983,0.240983,0.240983,0.240983],\n",
    "[0.339714,0.339714,0.339714,0.339714,0.339714,0.339714],\n",
    "[0.130415,0.130415,0.130415,0.130415,0.130415,0.130415],\n",
    "[0.143260,0.143260,0.143260,0.143260,0.143260,0.143260],\n",
    "[0.211465,0.211465,0.211465,0.211465,0.211465,0.211465],\n",
    "[0.194187,0.194187,0.194187,0.194187,0.194187,0.194187],\n",
    "[0.185422,0.185422,0.185422,0.185422,0.185422,0.185422],\n",
    "[0.171973,0.171973,0.171973,0.171973,0.171973,0.171973],\n",
    "[0.152277,0.152277,0.152277,0.152277,0.152277,0.152277]])\n",
    "\n",
    "X = np.zeros((K, max_obs, N), dtype=np.int)\n",
    "for n, k in itertools.product(range(N), range(K)):\n",
    "    # n: user number\n",
    "    # T[n]: time of observation for user\n",
    "    # k: comorbidity number\n",
    "    \n",
    "    # Initialize comorbidities with initial comborbidity distribution (B0)\n",
    "    X[k, 0, n] = np.random.binomial(n=1, p=B0[k,S[n,0]])\n",
    "    \n",
    "    for time_step in range(1,max_obs):\n",
    "        state_not_changed = (S[n,time_step] == S[n,time_step-1])\n",
    "        comorb_already_present = (X[k,time_step-1,n]==1)\n",
    "        if state_not_changed or comorb_already_present:\n",
    "            X[k,time_step,n] = X[k,time_step-1,n]\n",
    "        else:\n",
    "            # If not, chance of comorbidity is a function of current state\n",
    "            X[k,time_step,n] = np.random.binomial(n=1, p=B[k,S[n,time_step]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = np.loadtxt('../data/synthetic/Z.txt')\n",
    "L = np.loadtxt('../data/synthetic/L.txt')\n",
    "\n",
    "O = np.zeros((Dd, max_obs,N), dtype=np.int) - 1\n",
    "for n in range(N):\n",
    "    for time_step in range(1,max_obs):\n",
    "        pO = 1 - (1-L)*np.prod(1-(X[:,time_step,n]*Z.T), axis=1)\n",
    "        codes = np.where(np.random.binomial(n=1, p=pO))[0]\n",
    "        O[0:len(codes),time_step,n] = codes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  11,  16,  42,  43,  46,  70,  72,  84,  88,  93, 108, 117,\n",
       "       129, 136, 148, 151, 205, 211, 222, 260, 264, 278, 280, 282, 302,\n",
       "       315, 316, 348, 358, 376, 386, 409, 410, 413, 428, 434, 457, 481,\n",
       "       487, 532, 582, 623, 695, 696,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "        -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "        -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "        -1,  -1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O[:,6,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(T, open('../data/X_layer_100_patients/T.pkl', 'wb'))\n",
    "dump(obs_jumps, open('../data/X_layer_100_patients/obs_jumps.pkl', 'wb'))\n",
    "#dump(X_input, open('../data/X_layer_100_patients/X_input.pkl', 'wb'))\n",
    "dump(O, open('../data/X_layer_100_patients/O_input.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute C Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_jumps[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pad the rest of the matrix with -1\n",
    "obs_jumps = np.insert(obs_jumps, max_obs-1, -1, axis=1)\n",
    "for n in range(N):\n",
    "    obs_jumps[n,T[n]-1:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert observed jumps to their appropriate array index\n",
    "step_sizes = np.sort(np.unique(obs_jumps))\n",
    "step_sizes = step_sizes[step_sizes > 0]\n",
    "obs_jump_ind = obs_jumps.copy()\n",
    "for index, step in enumerate(step_sizes):\n",
    "    obs_jump_ind[obs_jumps == step] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 0,  0,  0, ...,  0, -1, -1],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 0,  1,  0, ..., -1, -1, -1],\n",
       "       [ 0,  2,  0, ...,  0, -1, -1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_jump_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = np.vstack((obs_jump_ind.flatten()[:-1]*M**2, S.flatten()[:-1]*M, S.flatten()[1:]))\n",
    "q= np.sum(j[:,j[0,:] >= 0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  16,   14,    1,    1,    0,    0],\n",
       "        [   0,   64,   13,    2,    0,    0],\n",
       "        [   0,    0,   51,   26,    3,    1],\n",
       "        [   0,    0,    0,  151,   20,   12],\n",
       "        [   0,    0,    0,    0,   47,   42],\n",
       "        [   0,    0,    0,    0,    0, 1070]],\n",
       "\n",
       "       [[   1,    4,    0,    0,    0,    0],\n",
       "        [   0,    6,    0,    2,    0,    0],\n",
       "        [   0,    0,    2,    3,    1,    0],\n",
       "        [   0,    0,    0,    6,    5,    5],\n",
       "        [   0,    0,    0,    0,    0,    5],\n",
       "        [   0,    0,    0,    0,    0,  110]],\n",
       "\n",
       "       [[   1,    1,    0,    0,    0,    0],\n",
       "        [   0,    6,    9,    5,    0,    1],\n",
       "        [   0,    0,    1,    4,    3,    1],\n",
       "        [   0,    0,    0,    7,    3,   10],\n",
       "        [   0,    0,    0,    0,    1,    8],\n",
       "        [   0,    0,    0,    0,    0,  150]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(q, minlength=3*M*M).reshape((3,M,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  16,   14,    1,    1,    0,    0],\n",
       "        [   0,   64,   13,    2,    0,    0],\n",
       "        [   0,    0,   51,   26,    3,    1],\n",
       "        [   0,    0,    0,  151,   20,   12],\n",
       "        [   0,    0,    0,    0,   47,   42],\n",
       "        [   0,    0,    0,    0,    0, 1070]],\n",
       "\n",
       "       [[   1,    4,    0,    0,    0,    0],\n",
       "        [   0,    6,    0,    2,    0,    0],\n",
       "        [   0,    0,    2,    3,    1,    0],\n",
       "        [   0,    0,    0,    6,    5,    5],\n",
       "        [   0,    0,    0,    0,    0,    5],\n",
       "        [   0,    0,    0,    0,    0,  110]],\n",
       "\n",
       "       [[   1,    1,    0,    0,    0,    0],\n",
       "        [   0,    6,    9,    5,    0,    1],\n",
       "        [   0,    0,    1,    4,    3,    1],\n",
       "        [   0,    0,    0,    7,    3,   10],\n",
       "        [   0,    0,    0,    0,    1,    8],\n",
       "        [   0,    0,    0,    0,    0,  150]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "from theano import function\n",
    "import theano\n",
    "from theano.tensor.extra_ops import bincount\n",
    "theano.config.compute_test_value = 'ignore'\n",
    "theano.config.exception_verbosity = 'high'\n",
    "\n",
    "obs_jump_ind_T = T.as_tensor_variable(obs_jump_ind, 'obs_jump_ind_T')\n",
    "out0 = T.flatten(obs_jump_ind_T)[:-1]*M*M\n",
    "keep = (out0 >= 0).nonzero()\n",
    "\n",
    "S_T = T.lmatrix('S_T')\n",
    "\n",
    "\n",
    "out1 = T.flatten(S_T)[:-1]*M\n",
    "out2 = T.flatten(S_T)[1:]\n",
    "\n",
    "indices=out0+out1+out2\n",
    "k = indices[keep]\n",
    "f = function([S_T], bincount(k,minlength=3*M*M).reshape(shape=np.array([3,M,M])))\n",
    "C=f(S)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16,   14,    1,    1,    0,    0],\n",
       "       [   0,   64,   13,    2,    0,    0],\n",
       "       [   0,    0,   51,   26,    3,    1],\n",
       "       [   0,    0,    0,  151,   20,   12],\n",
       "       [   0,    0,    0,    0,   47,   42],\n",
       "       [   0,    0,    0,    0,    0, 1070]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ContinuousTimeMarkovModel.src.distributions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import Metropolis, Continuous, Beta\n",
    "from pymc3.distributions.discrete import Binomial\n",
    "\n",
    "class Observations(Continuous):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ContinuousTimeMarkovModel.src.forwardS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3.core import *\n",
    "from pymc3.step_methods.arraystep import ArrayStepShared\n",
    "from numpy import array, max, exp, cumsum, nested_iters, empty, searchsorted, ones\n",
    "from numpy.random import uniform\n",
    "\n",
    "from theano import theano\n",
    "from theano.gof.graph import inputs\n",
    "from theano.tensor import add \n",
    "from pymc3.theanof import make_shared_replacements\n",
    "\n",
    "from pymc3.distributions import transforms\n",
    "\n",
    "class sampleX(ArrayStepShared):\n",
    "    \"\"\"\n",
    "    Use forward sampling (equation 10) to sample a realization of S_t, t=1,...,T_n\n",
    "    given Q, B, and X constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, vars, model=None):\n",
    "        model = modelcontext(model)\n",
    "        #self.sh = ones(vars.dshape, vars.dtype)\n",
    "        self.vars = vars\n",
    "        shared = make_shared_replacements(vars, model)\n",
    "        super(sampleX, self).__init__(vars, shared)\n",
    "\n",
    "    def astep(self, q, logp):\n",
    "        return q\n",
    "        #p = array([logp(v * self.sh) for v in self.values])\n",
    "        #return categorical(p, self.var.dshape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-75e405eb411a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mstep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetropolis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mstep2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mstep3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetropolis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Arya/Achievemint/ContinuousTimeMarkovModel/src/forwardS.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vars, X, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mshared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_shared_replacements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampleS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwardS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Arya/Achievemint/ContinuousTimeMarkovModel/src/forwardS.py\u001b[0m in \u001b[0;36msampleS\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msampleS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mB_printed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_printed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "with model:\n",
    "    pi = Dirichlet('pi', a = as_tensor_variable([0.5, 0.5, 0.5, 0.5, 0.5, 0.5]), shape=M)\n",
    "    Q = DiscreteObsMJP_unif_prior('Q', M=M, shape=(M,M))\n",
    "    \n",
    "    S = DiscreteObsMJP('S', pi=pi, Q=Q, Tn=Tn, observed_jumps=obs_jumps, shape=(Tn))\n",
    "\n",
    "    B0 = Beta('B0', alpha = 1, beta = 1, shape=(K,M))\n",
    "    B = Beta('B', alpha = 1, beta = 1, shape=(K,M))\n",
    "\n",
    "    Xobs = Comorbidities('Xobs', S=S, B0=B0,B=B, shape=(K, max_obs+1, N), observed = X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

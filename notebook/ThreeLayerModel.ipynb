{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defines the complete model in David's paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate single trajectory up to X level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "M = 6\n",
    "K = 10\n",
    "D = 250\n",
    "Tn = 20\n",
    "step_sizes = [1,2,4]\n",
    "\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%Rpush Tn M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(smfsb)\n",
    "#pi <- c(0.147026,0.102571,0.239819,0.188710,0.267137,0.054738)\n",
    "pi <- c(1,0,0,0,0,0)\n",
    "\n",
    "Q <- matrix(c(-0.631921,0.631921,0.000000,0.000000,0.000000,0.000000,\n",
    "    0.000000,-0.229485,0.229485,0.000000,0.000000,0.000000,\n",
    "    0.000000,0.000000,-0.450538,0.450538,0.000000,0.000000,\n",
    "    0.000000,0.000000,0.000000,-0.206042,0.206042,0.000000,\n",
    "    0.000000,0.000000,0.000000,0.000000,-0.609582,0.609582,\n",
    "    0.000000,0.000000,0.000000,0.000000,0.00001,-0.00001), nrow=M, ncol=M,byrow=TRUE)\n",
    "\n",
    "set.seed(1729)\n",
    "s<-rcfmc(1e3, Q, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step_sizes = [1,2,4]\n",
    "np.random.seed(1729)\n",
    "observed_jumps = np.random.choice(step_sizes, Tn-1)\n",
    "observed_times = np.insert(np.cumsum(observed_jumps),0,0)\n",
    "%Rpush observed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  2.,  2.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R S <- s(observed_times)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "19\n",
      "[2 4 2 2 4 2 2 2 1 2 2 2 4 1 1 1 1 4 2]\n",
      "[ 0  2  6  8 10 14 16 18 20 21 23 25 27 31 32 33 34 35 39 41]\n",
      "[ 0.  1.  1.  2.  2.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "%Rpull S\n",
    "print len(S)\n",
    "print len(observed_jumps)\n",
    "print observed_jumps\n",
    "print observed_times\n",
    "print S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(observed_jumps)\n",
    "#len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[0.000001,0.760000,0.720000,0.570000,0.700000,0.610000],\n",
    "[0.000001,0.460000,0.390000,0.220000,0.200000,0.140000],\n",
    "[0.000001,0.620000,0.620000,0.440000,0.390000,0.240000],\n",
    "[0.000001,0.270000,0.210000,0.170000,0.190000,0.070000],\n",
    "[0.000001,0.490000,0.340000,0.220000,0.160000,0.090000],\n",
    "[0.000001,0.620000,0.340000,0.320000,0.240000,0.120000],\n",
    "[0.000001,0.550000,0.390000,0.320000,0.290000,0.150000],\n",
    "[0.000001,0.420000,0.240000,0.170000,0.170000,0.110000],\n",
    "[0.000001,0.310000,0.300000,0.230000,0.190000,0.110000],\n",
    "[0.000001,0.470000,0.340000,0.190000,0.190000,0.110000]])\n",
    "\n",
    "B0 = np.array([[0.410412,0.410412,0.418293,0.418293,0.429890,0.429890],\n",
    "[0.240983,0.240983,0.240983,0.240983,0.240983,0.240983],\n",
    "[0.339714,0.339714,0.339714,0.339714,0.339714,0.339714],\n",
    "[0.130415,0.130415,0.130415,0.130415,0.130415,0.130415],\n",
    "[0.143260,0.143260,0.143260,0.143260,0.143260,0.143260],\n",
    "[0.211465,0.211465,0.211465,0.211465,0.211465,0.211465],\n",
    "[0.194187,0.194187,0.194187,0.194187,0.194187,0.194187],\n",
    "[0.185422,0.185422,0.185422,0.185422,0.185422,0.185422],\n",
    "[0.171973,0.171973,0.171973,0.171973,0.171973,0.171973],\n",
    "[0.152277,0.152277,0.152277,0.152277,0.152277,0.152277]])\n",
    "\n",
    "X_input = np.zeros((K, Tn))\n",
    "for k in range(K):\n",
    "    X_input[k,0] = np.random.binomial(n=1, p=B0[k,S[0]] )\n",
    "for i in range(1, len(S)-1):\n",
    "    for k in range(K):\n",
    "        if S[i] == S[i-1] or X_input[k,i-1] > 0.5:\n",
    "            X_input[k,i] = X_input[k,i-1]\n",
    "        else:\n",
    "            X_input[k,i] = np.random.binomial(n=1, p=B[k,S[i]])\n",
    "\n",
    "X_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import Continuous\n",
    "from pymc3.distributions import transforms\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nlinalg import eig, matrix_inverse\n",
    "from theano.compile.sharedvalue import shared\n",
    "\n",
    "#prior\n",
    "class DiscreteObsMJP_unif_prior(Continuous):\n",
    "\n",
    "    def __init__(self, n, transform=transforms.log, *args, **kwargs):\n",
    "        super(DiscreteObsMJP_unif_prior, self).__init__(transform=transform, *args, **kwargs)\n",
    "        Q_raw = np.ones((n,n-1))\n",
    "        self.n = n\n",
    "        self.mode = Q_raw\n",
    "\n",
    "    def logp(self, value):\n",
    "        return 0\n",
    "\n",
    "#likelihood\n",
    "class DiscreteObsMJP(Continuous):\n",
    "\n",
    "    def __init__(self, Q_raw, S, observed_jumps, *args, **kwargs):\n",
    "        super(DiscreteObsMJP, self).__init__(*args, **kwargs)\n",
    "        self.Q_raw = Q_raw\n",
    "        self.S = S\n",
    "        self.observed_jumps = observed_jumps\n",
    "        self.step_sizes = np.unique(observed_jumps)\n",
    "        \n",
    "        self.mode=0\n",
    "\n",
    "    #@as_op(itypes=[T.dmatrix], otypes=[T.cmatrix])\n",
    "    def convertFromRaw(self, Q_raw):\n",
    "\n",
    "        #get integer value and symbolic representation\n",
    "        nrows, ncols = Q_raw.transformed.dshape\n",
    "        nrows_s, ncols_s = Q_raw.shape \n",
    "\n",
    "        #create Q\n",
    "        Q = T.alloc(0.0, *(nrows_s, ncols_s+1))\n",
    "        Q.name = 'Q'\n",
    "\n",
    "        #fill Q\n",
    "        row_sums = Q_raw.sum(axis=1)\n",
    "        for i in range(0, nrows):\n",
    "            ind = 0\n",
    "            for j in range(0, ncols+1):\n",
    "                if i==j:\n",
    "                    Q = T.set_subtensor(Q[i,j], -row_sums[i])\n",
    "                else:\n",
    "                    Q = T.set_subtensor(Q[i,j], Q_raw[i,ind])\n",
    "                    ind += 1\n",
    "                    \n",
    "        return Q\n",
    "    \n",
    "    def computeC(self):\n",
    "        S = self.S\n",
    "        step_sizes = self.step_sizes\n",
    "        observed_jumps = self.observed_jumps\n",
    "        n_step_sizes = len(self.step_sizes)\n",
    "        \n",
    "        nrows_s, ncols_s = Q_raw.shape\n",
    "        n_step_sizes_s=shared(value=n_step_sizes, name='n_step_sizes_s')\n",
    "        \n",
    "        #create C\n",
    "        C_true = T.alloc(0, *(nrows_s, ncols_s+1, n_step_sizes_s))\n",
    "        C_true.name = 'C_true'\n",
    "        \n",
    "        #fill C\n",
    "        for i in range(len(observed_jumps)):\n",
    "            tau = observed_jumps[i]\n",
    "            tau_index = 0\n",
    "            for j in range(len(step_sizes)):\n",
    "                if tau == step_sizes[j]:\n",
    "                    tau_index = j\n",
    "                    break\n",
    "            #tau_index = np.where(step_sizes==tau)[0].item()\n",
    "            \n",
    "            Ci = S[i]\n",
    "            Cj = S[i+1]\n",
    "            C_true = T.set_subtensor(C_true[Ci, Cj, tau_index], \n",
    "                                     C_true[Ci, Cj, tau_index]+1)\n",
    "        \n",
    "        return C_true\n",
    "    \n",
    "    def logp(self, C):\n",
    "        Q_raw = self.Q_raw\n",
    "        step_sizes = self.step_sizes\n",
    "\n",
    "        Q = self.convertFromRaw(Q_raw)\n",
    "        Q_complex = T.cast(Q, 'complex64')\n",
    "\n",
    "        C_true = self.computeC()\n",
    "        \n",
    "        l = 0.0\n",
    "        for i in range(0, len(step_sizes)):\n",
    "            #get P(tau)\n",
    "            lambdas, U = eig(Q_complex)\n",
    "            \n",
    "            tau = step_sizes[i]\n",
    "            exp_tD = T.diag(T.exp(tau*lambdas))\n",
    "\n",
    "            U_inv = matrix_inverse(U)\n",
    "\n",
    "            P = U.dot(exp_tD).dot(U_inv)\n",
    "        \n",
    "            #compute likelihood in terms of P(tau)\n",
    "            l += T.sum(C_true[:,:,i]*T.log(P))\n",
    "            \n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import Metropolis, Continuous, Beta\n",
    "\n",
    "class Comorbidities(Continuous):\n",
    "    def __init__(self, S, B, shape, *args, **kwargs):\n",
    "        super(Comorbidities, self).__init__(*args, **kwargs)\n",
    "        X = np.ones(shape)\n",
    "        self.shape = shape\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.mode = X\n",
    "\n",
    "    def logp(self, value):\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "class HMM_Blank(Continuous):\n",
    "    def __init__(self, shape, *args, **kwargs):\n",
    "        super(HMM_Blank, self).__init__(shape = shape, dtype='int32', *args, **kwargs)\n",
    "        S = np.ones(shape, dtype=np.int32)\n",
    "        self.shape = shape\n",
    "        self.mode = S\n",
    "\n",
    "    def logp(self, value):\n",
    "        return 0\n",
    "\n",
    "\n",
    "class Observations(Continuous):\n",
    "    pass\n",
    "\n",
    "class sampleS(Metropolis):\n",
    "    pass\n",
    "\n",
    "class sampleS(Metropolis):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on May 12, 2012\n",
    "\n",
    "@author: john\n",
    "'''\n",
    "from pymc3.core import *\n",
    "from pymc3.step_methods.arraystep import ArrayStepShared\n",
    "from numpy import array, max, exp, cumsum, nested_iters, empty, searchsorted, ones\n",
    "from numpy.random import uniform\n",
    "\n",
    "from theano.gof.graph import inputs\n",
    "from theano.tensor import add \n",
    "from pymc3.theanof import make_shared_replacements\n",
    "\n",
    "\n",
    "class sampleS(ArrayStepShared):\n",
    "    \"\"\"\n",
    "    Use forward sampling (equation 10) to sample a realization of S_t, t=1,...,T_n\n",
    "    given Q, B, and X constant.\n",
    "    \"\"\"\n",
    "    # TODO: It would be great to come up with a way to make\n",
    "    # ElemwiseCategoricalStep  more general (handling more complex elementwise\n",
    "    # variables)\n",
    "    def __init__(self, vars, model=None):\n",
    "        model = modelcontext(model)\n",
    "        #self.sh = ones(vars.dshape, vars.dtype)\n",
    "        self.vars = vars\n",
    "        shared = make_shared_replacements(vars, model)\n",
    "        super(sampleS, self).__init__(vars, shared)\n",
    "\n",
    "    def astep(self, q, logp):\n",
    "        return q\n",
    "        #p = array([logp(v * self.sh) for v in self.values])\n",
    "        #return categorical(p, self.var.dshape)\n",
    "\n",
    "\n",
    "class sampleX(ArrayStepShared):\n",
    "    \"\"\"\n",
    "    Use forward sampling (equation 10) to sample a realization of S_t, t=1,...,T_n\n",
    "    given Q, B, and X constant.\n",
    "    \"\"\"\n",
    "    # TODO: It would be great to come up with a way to make\n",
    "    # ElemwiseCategoricalStep  more general (handling more complex elementwise\n",
    "    # variables)\n",
    "    def __init__(self, vars, model=None):\n",
    "        model = modelcontext(model)\n",
    "        #self.sh = ones(vars.dshape, vars.dtype)\n",
    "        self.vars = vars\n",
    "        shared = make_shared_replacements(vars, model)\n",
    "        super(sampleX, self).__init__(vars, shared)\n",
    "\n",
    "    def astep(self, q, logp):\n",
    "        return q\n",
    "        #p = array([logp(v * self.sh) for v in self.values])\n",
    "        #return categorical(p, self.var.dshape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pm.Model()\n",
    "\n",
    "with model:\n",
    "    Q_raw = DiscreteObsMJP_unif_prior('Q_raw', n=M, shape=(M,M-1))\n",
    "    \n",
    "    S = HMM_Blank('S', shape=(Tn,1) )\n",
    "    C = DiscreteObsMJP('C', Q_raw=Q_raw, S=S, observed_jumps=observed_jumps)\n",
    "\n",
    "    B = Beta('B', alpha = 1, beta = 1, shape=(K,M))\n",
    "    X = Comorbidities('X', S=S, B=B, shape=(K, Tn), observed = X_input)\n",
    "\n",
    "    #Z = Beta('Z')\n",
    "    #L = Beta('L')\n",
    "    #O = Observations('O', X=X, Z=Z, L=L, shape=(D, T_n))\n",
    "\n",
    "with model:\n",
    "    step1 = Metropolis(vars=[Q_raw])\n",
    "    step2 = sampleS(vars=[S])\n",
    "    step3 = Metropolis(vars=[B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
